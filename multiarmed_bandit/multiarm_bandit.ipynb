{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Arm Bandit Algorithm\n",
    "\n",
    "## References\n",
    "1. *Practical Statistics for Data Scientists: 50 Essential Concepts* by Peter Bruce Andrew Bruce\n",
    "1. [Multi-armed bandit](https://en.wikipedia.org/wiki/Multi-armed_bandit) on Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "**Multi-arm bandit**\n",
    "An imaginary slot machine with multiple arms for the customer to choose from, each with different payoffs, here taken to be an analogy for a multitreatment experiment.\n",
    "\n",
    "Algorithm is popular A/B testing.\n",
    "\n",
    "Each arm has an unknown probability of win or, in general, expected payoff.\n",
    "You have only limited number of tries.\n",
    "Your goal is to maximize the payoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration vs. Exploitation\n",
    "\n",
    "Exploration: you spend the first several rounds randomly selecting \"arms\", then pick the best one and use only that one. But you potentially wasted these rounds by not choosing the best earlier.\n",
    "\n",
    "Exploitation: you try to figure out quickly which is the best arm and use only it. But you may have picked the wrong one. In that case you should have spent more time exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandit algorithms\n",
    "Hybrid approach. Keep exploring, but give preference the \"arm\" with the best results at that moment.\n",
    "\n",
    "### Epsilon-greedy algorithm\n",
    "\n",
    "1. Generate a random number between 0 and 1. \n",
    "1. If the number lies between 0 and epsilon (where epsilon is a number between 0 and 1, typically fairly small), pick the \"arm\" at random\n",
    "3. If the number is â‰¥ epsilon, show whichever offer has had the highest response rate to date.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thompson Sampling\n",
    "\n",
    "Dynamically adjust the probability we pick samples based on the currently available information.\n",
    "\n",
    "Bayes rule:\n",
    "\n",
    "$$ p(A|B) = \\frac{p(B|A) p(A)}{p(B)} $$\n",
    "\n",
    "In our case we would like to estimate the probability distribution of \"arms\" parameters given the data:\n",
    "\n",
    "We model the multi-arm bandit using a Multinomial distribution (in case of two arms: Binomial): the probability that we have $n_1$ successes for the first \"arm\", $n_2$ successes for the second \"arm\", etc. is:\n",
    "\n",
    "$$ p(n_1 ... n_k) = \\frac{n!}{n_1! ... n_k!} \\pi_1^{n_1} ... \\pi_k^{n_k}$$\n",
    "\n",
    "Here  $n = \\sum_{i=1}^k{n_i} $ and $\\sum_{i=1}^k{ \\pi_i }= 1$\n",
    "\n",
    "The prior distribution of the parameters $\\pi$ is Dirichlet distribution:\n",
    "\n",
    "$$ p(\\pi) = \\frac{1}{B(\\alpha)}  \\prod_{i=1}^k {\\pi_i^{\\alpha_i-1}} $$\n",
    "\n",
    "Since we don't know anything about the multi-armed bandit until we started interacting with it, it makes sense to set all $\\alpha$ to the same value, for example, to 1.\n",
    "\n",
    "Since the Dirichlet distribution is a conjugate prior of the Multinomial distribution, the posterior distribution is also Dirichlet distribution with parameters $\\alpha_i = n_i$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the algorithm is as follows:\n",
    "1. Recalculate the parameters of the posterior distribution\n",
    "2. Draw a sample from the posterior distribution\n",
    "3. Find the max $\\pi_i$ and use the \"arm\" corresponding to this index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates that even after 10 trials the worse option can outperform the better option. So if we naively base our decision on the first 10 trials, we may not get the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def draw(p):\n",
    "    return 1 if random.random() <= p else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(6)\n",
    "p_a = 0.5\n",
    "p_b = 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 0 B: 0\n",
      "A: 1 B: 1\n",
      "A: 1 B: 0\n",
      "A: 1 B: 0\n",
      "A: 1 B: 0\n",
      "A: 1 B: 0\n",
      "A: 0 B: 1\n",
      "A: 0 B: 0\n",
      "A: 1 B: 0\n",
      "A: 0 B: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('A:',draw(p_a), 'B:', draw(p_b))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same parameters, but limit ourselves to only 100 attempts. The best we can get is $51, the worst - $50. \n",
    "First we will try epsilon-greedy strategy, and will try to see what is the best value of the epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(p_a, p_b, epsilon, max_attempts):\n",
    "    a_successes = 0\n",
    "    b_successes = 0\n",
    "    \n",
    "    for _ in range(max_attempts):\n",
    "        shold_random = n\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
